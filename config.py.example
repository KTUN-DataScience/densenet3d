from paths import Path

class Config:
    """
    Model training Configuration class
    -----

    Attributes:

    - arch: Name of architecture being used
    - learning_rate (float) - how many filters to add each layer (k in paper)
    - n_epoch (int) - how many layers in each pooling block
    - lr_patience:
    - momentum:
    - begin_epoch:
    - n_epochs:
    - lr_steps:
    - weight_decay:
    - nesterov:
    - dataset:
    - model:
    - width_mult:
    - batch_size:
    - n_threads:
    -  dampening:
    - modality:
    - sample_duration:
    - sample_size:
    - n_val_samples:
    - downsample:
    - optimiser:
    - cuda:
    - dataset_path:
    - annotation_path:
    - result_path:
    - n_classes:
    - initial_scale:
    - n_scales:
    - scale_step:
    - norm_value:
    - mean_dataset:
    - mean_norm:
    - std_norm: 

    Usage:
    ------

        from config import Config
        ``Config.learning_rate``
    """

    arch = 'Densenet'

    arch_type = 161

    learning_rate = 0.1

    lr_patience = 10

    momentum = 0.9

    begin_epoch = 1

    n_epochs = 100

    n_classes = 27

    lr_steps = [25, 40, 55, 70] # (lr_rate * (0.1 ** step_position ))  =>  (0.1 (0.1 ** 1))

    weight_decay = 1e-3

    nesterov = False

    dataset = 'jester'

    model = 'densenet3d'

    activation = 'relu' # options: 'relu' or 'leaky_relu'

    classifier = 'Linear' # options: 'Softmax' or 'Linear'

    negative_slope = 0.1
    
    train = True

    validation = True

    test = False

    seed = 1000

    width_mult = 1

    batch_size = 16

    n_threads = 16

    dampening = 0.9

    modality = 'RGB'

    sample_duration = 16

    sample_size = 112

    n_val_samples = 1

    downsample = 2

    optimizer = 'SGD' # options: 'Adam' or 'SGD'

    betas = (0.9, 0.999)

    eps = 1e-8

    amsgrad = False

    cuda = True

    dataset_path = Path.dataset_path

    annotation_path = Path.annotation_path

    result_path = Path.result_path

    resume_path = ''

    initial_scale = 1

    n_scales = 5

    scale_step = 0.84089641525

    norm_value = 255

    mean_dataset = 'activitynet'

    dataset = ''

    store_name = ''

    train_crop = 'random'

    mean_norm = False,

    std_norm = False,

    softmax_in_test = True

    scale_in_test = 1.0

    test_subset = 'val'

    crop_position_in_test = 'c'
    
   
